{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-15T03:16:23.082942Z","iopub.execute_input":"2023-03-15T03:16:23.083425Z","iopub.status.idle":"2023-03-15T03:16:23.093059Z","shell.execute_reply.started":"2023-03-15T03:16:23.083385Z","shell.execute_reply":"2023-03-15T03:16:23.091750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the data","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nimport torchvision.models as models\nimport warnings\n# Ignore all warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:23.102659Z","iopub.execute_input":"2023-03-15T03:16:23.103219Z","iopub.status.idle":"2023-03-15T03:16:23.110022Z","shell.execute_reply.started":"2023-03-15T03:16:23.103184Z","shell.execute_reply":"2023-03-15T03:16:23.108902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:23.132238Z","iopub.execute_input":"2023-03-15T03:16:23.132754Z","iopub.status.idle":"2023-03-15T03:16:23.138366Z","shell.execute_reply.started":"2023-03-15T03:16:23.132727Z","shell.execute_reply":"2023-03-15T03:16:23.137217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv',dtype=np.float32)\ntrain\n","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:23.143974Z","iopub.execute_input":"2023-03-15T03:16:23.144964Z","iopub.status.idle":"2023-03-15T03:16:25.516869Z","shell.execute_reply.started":"2023-03-15T03:16:23.144900Z","shell.execute_reply":"2023-03-15T03:16:25.515694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_train = len(train)\nn_pixels = len(train.columns) - 1\nn_class = len(set(train['label']))\n\nprint('Number of training samples: {0}'.format(n_train))\nprint('Number of training pixels: {0}'.format(n_pixels))\nprint('Number of classes: {0}'.format(n_class))","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:25.518888Z","iopub.execute_input":"2023-03-15T03:16:25.519433Z","iopub.status.idle":"2023-03-15T03:16:25.533233Z","shell.execute_reply.started":"2023-03-15T03:16:25.519387Z","shell.execute_reply":"2023-03-15T03:16:25.532046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv',dtype=np.float32)\ntest","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:25.535123Z","iopub.execute_input":"2023-03-15T03:16:25.536112Z","iopub.status.idle":"2023-03-15T03:16:26.993995Z","shell.execute_reply.started":"2023-03-15T03:16:25.536071Z","shell.execute_reply":"2023-03-15T03:16:26.992861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_test = len(test)\nn_pixels = len(test.columns)\n\nprint('Number of test samples: {0}'.format(n_test))\nprint('Number of test pixels: {0}'.format(n_pixels))","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:26.997590Z","iopub.execute_input":"2023-03-15T03:16:26.997997Z","iopub.status.idle":"2023-03-15T03:16:27.004519Z","shell.execute_reply.started":"2023-03-15T03:16:26.997958Z","shell.execute_reply":"2023-03-15T03:16:27.003028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For below code, X_train = X_train / 255 is dividing the training data set by 255. This is likely because the image data is typically represented by pixel values ranging from 0 to 255, with 0 being black and 255 being white. Normalizing the pixel values to be between 0 and 1 can make it easier for the model to converge during training.\n\n X_test = test / 255 is performing the same normalization on the test data set.\n\nX_train = X_train.values.reshape(-1,28,28,1) is reshaping the training data set. The -1 argument is telling NumPy to infer the size of the first dimension of the array based on the size of the other dimensions. In this case, the other dimensions are 28 and 28, which correspond to the width and height of the images. The 1 in the last dimension corresponds to the number of color channels in the image, which is one since the images are likely grayscale. This reshaping operation is necessary because most machine learning frameworks expect input data to be in a specific format, typically a 4-dimensional tensor of shape (batch_size, height, width, channels).","metadata":{}},{"cell_type":"code","source":"y_train = train.label.values\nx_train = train.loc[:, train.columns != 'label'].values\nx_train = x_train/255\nx_test = test/255\nx_train = x_train.reshape(-1,28,28,1)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:27.006820Z","iopub.execute_input":"2023-03-15T03:16:27.007290Z","iopub.status.idle":"2023-03-15T03:16:27.144849Z","shell.execute_reply.started":"2023-03-15T03:16:27.007249Z","shell.execute_reply":"2023-03-15T03:16:27.143758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# PREVIEW IMAGES\nplt.figure(figsize=(15,4.5))\nfor i in range(30):  \n    plt.subplot(3, 10, i+1)\n    plt.imshow(x_train[i].reshape((28,28)),cmap=plt.cm.binary)\n    plt.axis('off')\nplt.subplots_adjust(wspace=-0.1, hspace=-0.1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:27.147593Z","iopub.execute_input":"2023-03-15T03:16:27.148317Z","iopub.status.idle":"2023-03-15T03:16:28.279444Z","shell.execute_reply.started":"2023-03-15T03:16:27.148276Z","shell.execute_reply":"2023-03-15T03:16:28.278285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = x_train.reshape((-1,1,28,28))\nx_test = x_test.values.reshape(-1,1,28,28)\nx_train = np.stack((x_train,)*3, axis=1)\nx_train = np.squeeze(x_train, axis=2)\nx_train.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:28.280787Z","iopub.execute_input":"2023-03-15T03:16:28.281622Z","iopub.status.idle":"2023-03-15T03:16:28.487434Z","shell.execute_reply.started":"2023-03-15T03:16:28.281582Z","shell.execute_reply":"2023-03-15T03:16:28.486452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test = np.stack((x_test,)*3, axis=1)\nx_test = np.squeeze(x_test, axis=2)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:28.488852Z","iopub.execute_input":"2023-03-15T03:16:28.489281Z","iopub.status.idle":"2023-03-15T03:16:28.624517Z","shell.execute_reply.started":"2023-03-15T03:16:28.489236Z","shell.execute_reply":"2023-03-15T03:16:28.623357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = torch.from_numpy(y_train).type(torch.LongTensor)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:28.626144Z","iopub.execute_input":"2023-03-15T03:16:28.626852Z","iopub.status.idle":"2023-03-15T03:16:28.633664Z","shell.execute_reply.started":"2023-03-15T03:16:28.626811Z","shell.execute_reply":"2023-03-15T03:16:28.632480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"x_train, x_test and y_train are made as tensors","metadata":{}},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:28.638595Z","iopub.execute_input":"2023-03-15T03:16:28.638926Z","iopub.status.idle":"2023-03-15T03:16:28.647546Z","shell.execute_reply.started":"2023-03-15T03:16:28.638895Z","shell.execute_reply":"2023-03-15T03:16:28.646289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Transform = transforms.Compose([transforms.ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:28.651020Z","iopub.execute_input":"2023-03-15T03:16:28.651344Z","iopub.status.idle":"2023-03-15T03:16:28.656802Z","shell.execute_reply.started":"2023-03-15T03:16:28.651283Z","shell.execute_reply":"2023-03-15T03:16:28.655394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH = 32\nepochs = 23\nLR = 1e-3","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:28.658372Z","iopub.execute_input":"2023-03-15T03:16:28.658859Z","iopub.status.idle":"2023-03-15T03:16:28.668057Z","shell.execute_reply.started":"2023-03-15T03:16:28.658817Z","shell.execute_reply":"2023-03-15T03:16:28.667066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below code defines a custom PyTorch dataset class named GetData, which inherits from the Dataset class. This custom dataset class is designed to load data from a dataset for use with PyTorch models.\n\nThe __init__ method of the GetData class takes three arguments: x_train, y_train, and Transform. x_train is a tensor containing the input features for the dataset, y_train is a tensor containing the corresponding target labels for the dataset, and Transform is a PyTorch transform object that is applied to the input features during loading.\n\nIn the __init__ method, the input features and target labels are stored as instance variables self.X and self.Y, respectively. The transform object is also stored as an instance variable self.transform.\n\nThe __len__ method returns the number of samples in the dataset, which is the length of the input features tensor self.X.\n\nThe __getitem__ method is used to retrieve a single sample from the dataset given its index. In this method, the transform object is applied to the input features tensor self.X[index]. The resulting tensor is then permuted using the permute method to change its dimensions from (channels, height, width) to (height, width, channels). The contiguous method is called to ensure that the memory layout of the resulting tensor is contiguous. Finally, a tuple containing the transformed input features and the corresponding target label is returned.","metadata":{}},{"cell_type":"code","source":"class GetData(Dataset):\n    def __init__(self, x_train, y_train, Transform):\n        self.X = x_train\n        self.transform = Transform\n        self.Y = y_train\n        \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, index):\n        return self.transform(self.X[index]).permute((1, 2, 0)).contiguous(), self.Y[index]","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:28.669151Z","iopub.execute_input":"2023-03-15T03:16:28.669461Z","iopub.status.idle":"2023-03-15T03:16:28.679365Z","shell.execute_reply.started":"2023-03-15T03:16:28.669433Z","shell.execute_reply":"2023-03-15T03:16:28.677914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset = GetData(x_train,y_train,Transform)\ntrainloader = DataLoader(trainset, batch_size=BATCH, shuffle=True, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:28.680932Z","iopub.execute_input":"2023-03-15T03:16:28.681548Z","iopub.status.idle":"2023-03-15T03:16:28.691282Z","shell.execute_reply.started":"2023-03-15T03:16:28.681510Z","shell.execute_reply":"2023-03-15T03:16:28.690166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"next(iter(trainloader))[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:28.692468Z","iopub.execute_input":"2023-03-15T03:16:28.693244Z","iopub.status.idle":"2023-03-15T03:16:28.940536Z","shell.execute_reply.started":"2023-03-15T03:16:28.693208Z","shell.execute_reply":"2023-03-15T03:16:28.939401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below  code is creating nets number of convolutional neural network (CNN) models with the same architecture.\n\nEach model is created using the nn.Sequential() module, which allows us to stack multiple layers together to form the model. The architecture of the model consists of several convolutional layers, activation functions (ReLU), batch normalization layers, dropout layers, and fully connected layers (linear).\n\nThe nn.Conv2d() module creates a 2-dimensional convolutional layer with a specified number of input channels (1), output channels (32, 64, or 128), kernel size (3 or 5), padding (1 or 2), and stride (2). The ReLU activation function is applied after each convolutional layer to introduce non-linearity, and the batch normalization layer is used to improve the convergence and generalization of the network. Dropout layers are added to prevent overfitting.\n\nFinally, the model is optimized using the Adam optimizer and trained using the Cross-Entropy loss function. The optimizer is used to update the model's parameters during backpropagation, while the loss function calculates the difference between the predicted and actual class labels of the input data.\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Model of multiple CNNs","metadata":{}},{"cell_type":"code","source":"model= nn.Sequential(\n    nn.Conv2d(3,32,kernel_size =3, padding =1),\n    nn.ReLU(),\n    nn.BatchNorm2d(32),\n    nn.Conv2d(32, 32, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(32),\n    nn.Conv2d(32, 32, kernel_size=5, padding=2, stride=2),\n    nn.ReLU(),\n    nn.BatchNorm2d(32),\n    nn.Dropout2d(0.4),\n    nn.Conv2d(32, 64, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(64),\n    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(64),\n    nn.Conv2d(64, 64, kernel_size=5, padding=2, stride=2),\n    nn.ReLU(),\n    nn.BatchNorm2d(64),\n    nn.Dropout2d(0.4),\n    nn.Conv2d(64, 128, kernel_size=4),\n    nn.ReLU(),\n    nn.BatchNorm2d(128),\n    nn.Flatten(),\n    nn.Dropout(0.4),\n    nn.Linear(2048, 10)\n    )\nmodel = model.to(DEVICE)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:28.942665Z","iopub.execute_input":"2023-03-15T03:16:28.943074Z","iopub.status.idle":"2023-03-15T03:16:28.965825Z","shell.execute_reply.started":"2023-03-15T03:16:28.943025Z","shell.execute_reply":"2023-03-15T03:16:28.964616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below code represents a typical training loop in PyTorch for training a neural network model for a given number of epochs.\n\nThe outer loop iterates over the range of epochs.\ntr_loss is the training loss that accumulates for each batch in the epoch.\ncorrect and total keep track of the number of correctly predicted labels and the total number of labels in the epoch.\nmodel.train() sets the model in training mode.\nThe inner loop iterates over the trainloader which loads the training data in batches. For each batch,\nthe inputs and labels are moved to the GPU device if available.\nThe forward pass is performed using the model on the input batch to obtain the outputs.\nThe loss is computed between the outputs and labels using a criterion such as cross-entropy.\nThe optimizer is zeroed out.\nThe backward pass is performed to compute the gradients and the optimizer is updated using these gradients to adjust the weights of the model.\nThe batch loss is accumulated to the epoch loss.\nThe predicted labels are computed by taking the argmax of the output probabilities.\ncorrect and total are updated based on the number of correct predictions in the batch.\ntrain_acc is computed by dividing the number of correctly predicted labels by the total number of labels and multiplying by 100 to obtain the percentage accuracy.\nAfter the training epoch is completed, the model is set to evaluation mode using model.eval().\nThe validation loss is computed in a similar way to the training loss but using the validation dataset.\nval_acc is computed in a similar way to train_acc.\nFinally, the epoch number, epoch loss, train accuracy and validation accuracy are printed for the epoch.","metadata":{}},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"for epoch in range(epochs):\n    tr_loss = 0.0\n    correct = 0\n    total = 0\n    model = model.train()\n\n    for i, (images, labels) in enumerate(trainloader):\n        \n        images = images.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        outputs = model(images)\n        loss = criterion(outputs,labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        tr_loss += loss.detach().item()\n        _,predicted = torch.max(outputs.data,1)\n        total+=labels.size(0)\n        correct += (predicted ==labels).sum().item()\n        \n    train_acc = 100 * correct/total\n\n        \n    val_loss = 0.0\n    correct = 0\n    total = 0\n    model = model.eval()\n    _, predicted = torch.max(outputs.data, 1)\n    total+=labels.size(0)\n    correct += (predicted ==labels).sum().item()\n    val_acc = 100 * correct / total\n    print('Epoch: %d | Loss: %.4f |Train accuracy=:%.5f, Validation accuracy=:%.5f' \n          %(epoch, tr_loss / i ,train_acc,val_acc))","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:16:28.967557Z","iopub.execute_input":"2023-03-15T03:16:28.967929Z","iopub.status.idle":"2023-03-15T03:21:44.777125Z","shell.execute_reply.started":"2023-03-15T03:16:28.967892Z","shell.execute_reply":"2023-03-15T03:21:44.775773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv(\"/kaggle/input/digit-recognizer/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:21:44.778959Z","iopub.execute_input":"2023-03-15T03:21:44.779727Z","iopub.status.idle":"2023-03-15T03:21:44.801198Z","shell.execute_reply.started":"2023-03-15T03:21:44.779677Z","shell.execute_reply":"2023-03-15T03:21:44.800257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    model.eval()\n    sample['Label'] = model(torch.from_numpy(x_test).to(DEVICE)).cpu().argmax(dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:21:44.803091Z","iopub.execute_input":"2023-03-15T03:21:44.803853Z","iopub.status.idle":"2023-03-15T03:21:45.388308Z","shell.execute_reply.started":"2023-03-15T03:21:44.803814Z","shell.execute_reply":"2023-03-15T03:21:45.387211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T03:21:45.390038Z","iopub.execute_input":"2023-03-15T03:21:45.390428Z","iopub.status.idle":"2023-03-15T03:21:45.424066Z","shell.execute_reply.started":"2023-03-15T03:21:45.390387Z","shell.execute_reply":"2023-03-15T03:21:45.423081Z"},"trusted":true},"execution_count":null,"outputs":[]}]}